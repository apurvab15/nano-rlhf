=== Starting run for dataset size 10000 ===
Timestamp: Tue Oct 21 08:47:41 PM CDT 2025
----------------------------------------------
>>> Training...
tokens per iteration will be: 1,024
/afs/cs.wisc.edu/u/a/p/apurvaashok/foundational_model/nanoGPT/nanoGPT_venv/lib/python3.10/site-packages/torch/backends/__init__.py:46: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)
  self.setter(val)
found vocab_size = 82 (inside data/taylor_swift_lyrics_10000/meta.pkl)
Initializing a new model from scratch
number of parameters: 10.65M
/afs/cs.wisc.edu/u/a/p/apurvaashok/foundational_model/nanoGPT/train.py:196: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))
num decayed parameter tensors: 26, with 10,697,472 parameters
num non-decayed parameter tensors: 13, with 4,992 parameters
using fused AdamW: True
compiling the model... (takes a ~minute)
/afs/cs.wisc.edu/u/a/p/apurvaashok/foundational_model/nanoGPT/nanoGPT_venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:2772: UserWarning: NVIDIA GeForce RTX 2080 Ti does not support bfloat16 compilation natively, skipping
  warnings.warn(
step 0: train loss 4.4938, val loss 4.4828
/afs/cs.wisc.edu/u/a/p/apurvaashok/foundational_model/nanoGPT/nanoGPT_venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:2772: UserWarning: NVIDIA GeForce RTX 2080 Ti does not support bfloat16 compilation natively, skipping
  warnings.warn(
/afs/cs.wisc.edu/u/a/p/apurvaashok/foundational_model/nanoGPT/nanoGPT_venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:2772: UserWarning: NVIDIA GeForce RTX 2080 Ti does not support bfloat16 compilation natively, skipping
  warnings.warn(
/afs/cs.wisc.edu/u/a/p/apurvaashok/foundational_model/nanoGPT/nanoGPT_venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:2772: UserWarning: NVIDIA GeForce RTX 2080 Ti does not support bfloat16 compilation natively, skipping
  warnings.warn(
iter 0: loss 4.5088, time 9510.83ms, mfu -100.00%
step 250: train loss 1.7909, val loss 2.3398
saving checkpoint to out/taylor_swift_lyrics/taylor_swift_lyrics_10000
iter 250: loss 1.8928, time 30903.11ms, mfu 0.00%
step 500: train loss 1.1296, val loss 2.3972
iter 500: loss 1.3241, time 3129.93ms, mfu 0.00%
step 750: train loss 0.6060, val loss 2.7619
iter 750: loss 0.9140, time 3235.08ms, mfu 0.00%
step 1000: train loss 0.2624, val loss 3.2004
iter 1000: loss 0.3904, time 2882.90ms, mfu 0.00%
step 1250: train loss 0.1386, val loss 3.5399
iter 1250: loss 0.2769, time 2876.54ms, mfu 0.00%
step 1500: train loss 0.0995, val loss 3.8830
iter 1500: loss 0.2442, time 3209.85ms, mfu 0.00%
step 1750: train loss 0.0812, val loss 4.0581
iter 1750: loss 0.1405, time 2886.60ms, mfu 0.00%
step 2000: train loss 0.0767, val loss 4.1951
iter 2000: loss 0.1620, time 3210.45ms, mfu 0.00%
>>> Generating samples...
/afs/cs.wisc.edu/u/a/p/apurvaashok/foundational_model/nanoGPT/nanoGPT_venv/lib/python3.10/site-packages/torch/backends/__init__.py:46: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)
  self.setter(val)
>>> Evaluating metrics...

===== Evaluation Metrics =====
KL Divergence (3-gram): 6.841620
Distinct-1: 0.0108
Distinct-2: 0.0753
==============================

Completed run for dataset size: 10000
Timestamp: Tue Oct 21 08:50:20 PM CDT 2025
==============================================
